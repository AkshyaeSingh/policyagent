# Policy agent!

## Technical Architecture
### Phase 1: Preference Extraction

Gamified app with swipeable policy scenarios
Progressive disclosure (start simple, get more nuanced)
Contextual questions based on user's revealed preferences
Visual/story-based scenarios rather than abstract policy language

### Phase 2: Agent Representation

Each person's preferences encoded as a vector/embedding
Agents understand trade-offs and priority rankings
Can extrapolate to new issues based on value patterns
Maintains uncertainty bounds on preferences

### Phase 3: Multi-Agent Negotiation

Agents find Pareto-optimal solutions
Weighted by demographic representation
Can simulate coalitions and compromises
Transparent negotiation logs

### Phase 4: Policy Output

Clear policy recommendations with confidence scores
Minority reports showing dissenting clusters
Simulation of expected outcomes
Audit trail of how decision was reached

## Key Innovations for Demo

Preference Learning: Show how agent learns complex preferences from simple swipes
Visualization: Beautiful latent space visualization showing preference clusters
Negotiation Theater: Live visualization of agents negotiating
Outcome Simulation: Show predicted effects of different policies


